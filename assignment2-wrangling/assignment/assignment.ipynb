{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling\n",
        "## `! git clone https://github.com/DS3001/wrangling`\n",
        "## Do Q2, and one of Q1 or Q3."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
      "metadata": {
        "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
      },
      "source": [
        "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
        "\n",
        "  1. Read the abstract. What is this paper about?\n",
        "\n",
        "The paper is about data tidying, or the reformatting of data into an easily analyzable format. Data tidying formats data into dataframes, where the columns in a matrix represent variables and the rows represent observations. The paper goes over a framework that makes the data tidying process easier.\n",
        "\n",
        "  2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?\n",
        "\n",
        "The tidy data standard is meant to \"facilitate the initial exploration and analysis of the data, nd to simplify the development of data analysis tools that work well together\". The standard helps data scientists focus on the actual domain problem, rather than the logistics of the data.\n",
        "\n",
        "  3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, it’s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\"\n",
        "\n",
        "  Sentence one relates to how tidy datasets are all alike because they all make the data cleaning process easier and follow the same standard, structure, and properties. There are a lot of ways that data can be messy, such as typos, missing data, unstructured data. Therefore, messy datasets are messy in their own way, making it more difficult to process.\n",
        "\n",
        "  Sentence two states that examining data that's at least somewhat structured can show us what are variables and what are observations. However, the second part of the sentence mentions a more global take on the terms themselves. The definition of variables and observations can vary from dataset to dataset, so it is difficult to pin down a concrete, universal intepretation for everyone.\n",
        "\n",
        "  4. Read Section 2.2. How does Wickham define values, variables, and observations?\n",
        "\n",
        "Wickham defines values as strings or numbers that belong to a variable and observation. A variable contains all values that measure the same attribute in the study. An observation contains all values measured for the same unit, which could contain values for multiple variables.\n",
        "\n",
        "  5. How is \"Tidy Data\" defined in section 2.3?\n",
        "\n",
        "Tidy Data is defined as a structure in which each variable forms a column, each observation forms a row, and each type of obserevational unit forms a table.\n",
        "\n",
        "\n",
        "  6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?\n",
        "\n",
        "The five most common problems with messy data sets are column headers are values instead of variable names, multiple variables are stored in one column, variables are stored in both rows and columns, multiple types of observational units are stored in the same table, and a single observational unit is stored in multiple tables.\n",
        "\n",
        "The data in Table 4 are messy because the column names are values and not variables. The column names represents ranges for the specific variable of income. Variables represent both the columns and the rows. Melting the dataset alleviates this problem by converting columns into rows. In table 4's case, the table would be restructured such that there is a religion column, an income column, and a frequency column. Then, each row would represent one observation and the table would be tidy. \n",
        "\n",
        "  7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?\n",
        "\n",
        "Table 11 is messy because some of the columns are values that represent the days of the month. So, there are multiple observations in one row. There is also a lot of empty data in table 11 due to its structure. Data represents both rows and columns. It has variables like year and month spread across columns (days of the month) and across rows (min and max temperature). The element column is not a variable, it contains two variables. \n",
        "\n",
        "Table 12 is tidy and molten because each row represents one observation. There is one variable per column and the year, month, and day are consolodated into one variable called date which makes the data easier to interpret.\n",
        "\n",
        "  8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?\n",
        "\n",
        "The chicken and egg problem with tidy data states that if the efficiency of tidy data is limited by the tidy tools that use it, then tidy tools will be closely linked with tidy data. Wickham hopes that the tidy framework will be just the beginning of a much larger effort to enhance the data cleaning process as well as the overall data science method."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
      "metadata": {
        "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
      },
      "source": [
        "**Q2.** This question provides some practice cleaning variables which have common problems.\n",
        "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
        "2. Categorical variable: For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
        "3. Dummy variable: For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
        "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "7db44123",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "a978f83e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Host Id</th>\n",
              "      <th>Host Since</th>\n",
              "      <th>Name</th>\n",
              "      <th>Neighbourhood</th>\n",
              "      <th>Property Type</th>\n",
              "      <th>Review Scores Rating (bin)</th>\n",
              "      <th>Room Type</th>\n",
              "      <th>Zipcode</th>\n",
              "      <th>Beds</th>\n",
              "      <th>Number of Records</th>\n",
              "      <th>Number Of Reviews</th>\n",
              "      <th>Price</th>\n",
              "      <th>Review Scores Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5162530</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 Bedroom in Prime Williamsburg</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>11249.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33134899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sunny, Private room in Bushwick</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private room</td>\n",
              "      <td>11206.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39608626</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sunny Room in Harlem</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private room</td>\n",
              "      <td>10032.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "      <td>6/26/2008</td>\n",
              "      <td>Gorgeous 1 BR with Private Balcony</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>10024.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>199</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "      <td>6/26/2008</td>\n",
              "      <td>Trendy Times Square Loft</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>95.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>10036.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>549</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Host Id Host Since                                Name Neighbourhood   \\\n",
              "0   5162530        NaN     1 Bedroom in Prime Williamsburg       Brooklyn   \n",
              "1  33134899        NaN     Sunny, Private room in Bushwick       Brooklyn   \n",
              "2  39608626        NaN                Sunny Room in Harlem      Manhattan   \n",
              "3       500  6/26/2008  Gorgeous 1 BR with Private Balcony      Manhattan   \n",
              "4       500  6/26/2008            Trendy Times Square Loft      Manhattan   \n",
              "\n",
              "  Property Type  Review Scores Rating (bin)        Room Type  Zipcode  Beds  \\\n",
              "0     Apartment                         NaN  Entire home/apt  11249.0   1.0   \n",
              "1     Apartment                         NaN     Private room  11206.0   1.0   \n",
              "2     Apartment                         NaN     Private room  10032.0   1.0   \n",
              "3     Apartment                         NaN  Entire home/apt  10024.0   3.0   \n",
              "4     Apartment                        95.0     Private room  10036.0   3.0   \n",
              "\n",
              "   Number of Records  Number Of Reviews Price  Review Scores Rating  \n",
              "0                  1                  0   145                   NaN  \n",
              "1                  1                  1    37                   NaN  \n",
              "2                  1                  1    28                   NaN  \n",
              "3                  1                  0   199                   NaN  \n",
              "4                  1                 39   549                  96.0  "
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 1\n",
        "airbnb_df = pd.read_csv('./data/airbnb_hw.csv')\n",
        "airbnb_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "4421795b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method Series.unique of 0        145\n",
            "1         37\n",
            "2         28\n",
            "3        199\n",
            "4        549\n",
            "        ... \n",
            "30473    300\n",
            "30474    125\n",
            "30475     80\n",
            "30476     35\n",
            "30477     80\n",
            "Name: Price, Length: 30478, dtype: object> \n",
            "\n",
            "<bound method Series.unique of 0        145\n",
            "1         37\n",
            "2         28\n",
            "3        199\n",
            "4        549\n",
            "        ... \n",
            "30473    300\n",
            "30474    125\n",
            "30475     80\n",
            "30476     35\n",
            "30477     80\n",
            "Name: Price, Length: 30478, dtype: object> \n",
            "\n",
            "Number of missing values after coercion:  0\n"
          ]
        }
      ],
      "source": [
        "price = airbnb_df['Price']\n",
        "\n",
        "print(price.unique, '\\n')\n",
        "# when the price goes from 999 to 1,000, we want to remove the commas to make our data uniformly formatted\n",
        "price = price.str.replace(',','')\n",
        "print(price.unique, '\\n')\n",
        "# next, we want to coerce the values to numeric using Pandas' coerce\n",
        "price = pd.to_numeric(price, errors='coerce') \n",
        "\n",
        "# see how many missing values there are\n",
        "print(\"Number of missing values after coercion: \", sum(price.isnull()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "4b1e71d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of       index   Case Number                  Date    Year        Type  \\\n",
            "0         0    2020.02.05           05-Feb-2020  2020.0  Unprovoked   \n",
            "1         1  2020.01.30.R  Reported 30-Jan-2020  2020.0    Provoked   \n",
            "2         2    2020.01.17           17-Jan-2020  2020.0  Unprovoked   \n",
            "3         3    2020.01.16           16-Jan-2020  2020.0  Unprovoked   \n",
            "4         4    2020.01.13           13-Jan-2020  2020.0  Unprovoked   \n",
            "...     ...           ...                   ...     ...         ...   \n",
            "6457   6457       ND.0005           Before 1903     0.0  Unprovoked   \n",
            "6458   6458       ND.0004           Before 1903     0.0  Unprovoked   \n",
            "6459   6459       ND.0003             1900-1905     0.0  Unprovoked   \n",
            "6460   6460       ND.0002             1883-1889     0.0  Unprovoked   \n",
            "6461   6461       ND.0001             1845-1853     0.0  Unprovoked   \n",
            "\n",
            "                 Country               Area  \\\n",
            "0                    USA               Maui   \n",
            "1                BAHAMAS             Exumas   \n",
            "2              AUSTRALIA    New South Wales   \n",
            "3            NEW ZEALAND          Southland   \n",
            "4                    USA     North Carolina   \n",
            "...                  ...                ...   \n",
            "6457           AUSTRALIA  Western Australia   \n",
            "6458           AUSTRALIA  Western Australia   \n",
            "6459                 USA     North Carolina   \n",
            "6460              PANAMA                NaN   \n",
            "6461  CEYLON (SRI LANKA)   Eastern Province   \n",
            "\n",
            "                                 Location                  Activity  \\\n",
            "0                                     NaN  Stand-Up Paddle boarding   \n",
            "1                                     NaN                  Floating   \n",
            "2                           Windang Beach                   Surfing   \n",
            "3                             Oreti Beach                   Surfing   \n",
            "4                   Rodanthe, Dare County                   Surfing   \n",
            "...                                   ...                       ...   \n",
            "6457                          Roebuck Bay                    Diving   \n",
            "6458                                  NaN              Pearl diving   \n",
            "6459                       Ocracoke Inlet                  Swimming   \n",
            "6460                 Panama Bay 8ºN, 79ºW                       NaN   \n",
            "6461  Below the English fort, Trincomalee                  Swimming   \n",
            "\n",
            "                       Name  ... Unnamed: 246 Unnamed: 247 Unnamed: 248  \\\n",
            "0                       NaN  ...          NaN          NaN          NaN   \n",
            "1           Ana Bruna Avila  ...          NaN          NaN          NaN   \n",
            "2            Will Schroeter  ...          NaN          NaN          NaN   \n",
            "3               Jordan King  ...          NaN          NaN          NaN   \n",
            "4              Samuel Horne  ...          NaN          NaN          NaN   \n",
            "...                     ...  ...          ...          ...          ...   \n",
            "6457                   male  ...          NaN          NaN          NaN   \n",
            "6458                  Ahmun  ...          NaN          NaN          NaN   \n",
            "6459  Coast Guard personnel  ...          NaN          NaN          NaN   \n",
            "6460        Jules Patterson  ...          NaN          NaN          NaN   \n",
            "6461                   male  ...          NaN          NaN          NaN   \n",
            "\n",
            "     Unnamed: 249 Unnamed: 250 Unnamed: 251 Unnamed: 252 Unnamed: 253  \\\n",
            "0             NaN          NaN          NaN          NaN          NaN   \n",
            "1             NaN          NaN          NaN          NaN          NaN   \n",
            "2             NaN          NaN          NaN          NaN          NaN   \n",
            "3             NaN          NaN          NaN          NaN          NaN   \n",
            "4             NaN          NaN          NaN          NaN          NaN   \n",
            "...           ...          ...          ...          ...          ...   \n",
            "6457          NaN          NaN          NaN          NaN          NaN   \n",
            "6458          NaN          NaN          NaN          NaN          NaN   \n",
            "6459          NaN          NaN          NaN          NaN          NaN   \n",
            "6460          NaN          NaN          NaN          NaN          NaN   \n",
            "6461          NaN          NaN          NaN          NaN          NaN   \n",
            "\n",
            "     Unnamed: 254 Unnamed: 255  \n",
            "0             NaN          NaN  \n",
            "1             NaN          NaN  \n",
            "2             NaN          NaN  \n",
            "3             NaN          NaN  \n",
            "4             NaN          NaN  \n",
            "...           ...          ...  \n",
            "6457          NaN          NaN  \n",
            "6458          NaN          NaN  \n",
            "6459          NaN          NaN  \n",
            "6460          NaN          NaN  \n",
            "6461          NaN          NaN  \n",
            "\n",
            "[6462 rows x 257 columns]>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/4d/13vvrd7531qclhwg2svgst3c0000gn/T/ipykernel_68052/2146089193.py:2: DtypeWarning: Columns (10,17,18,19,20,21,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  sharkdf = pd.read_csv('../data/sharks.csv')\n"
          ]
        }
      ],
      "source": [
        "# Question 2\n",
        "sharkdf = pd.read_csv('../data/sharks.csv')\n",
        "print(sharkdf.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "41b1875c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unprovoked             4716\n",
            "Provoked                593\n",
            "Invalid                 552\n",
            "Sea Disaster            239\n",
            "Watercraft              142\n",
            "Boat                    109\n",
            "Boating                  92\n",
            "Questionable             10\n",
            "Unconfirmed               1\n",
            "Unverified                1\n",
            "Under investigation       1\n",
            "Boatomg                   1\n",
            "Name: Type, dtype: int64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "types = sharkdf['Type']\n",
        "print(types.value_counts(), '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "ee85fe01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unprovoked    4716\n",
            "Provoked       593\n",
            "Watercraft     583\n",
            "Name: Type, dtype: int64\n",
            "Unprovoked    4716\n",
            "Provoked       593\n",
            "Watercraft     583\n",
            "Name: Type, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\"\"\" \n",
        "Some of the column headings are similar, such as 'Boat', 'Boating', and 'Watercraft'. Questionable, Unconfirmed, Unverified, and Under \n",
        "Investigation seem to reference the same idea (invalid data) as well. Boatomg seems to be some sort of typo in the data, possibly meaning Boating.\n",
        "\"\"\"\n",
        "types = sharkdf['Type']\n",
        "# consolidate like columns into a single category\n",
        "types = types.replace(['Boat', 'Boating', 'Sea Disaster', 'Boatomg'], 'Watercraft')\n",
        "types = types.replace(['Questionable', 'Unconfirmed', 'Unverified', 'Under investigation', 'Invalid'], np.nan)\n",
        "print(types.value_counts())\n",
        "\n",
        "sharkdf['Type'] = types\n",
        "del types\n",
        "print(sharkdf['Type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "b1ea43e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  InternalStudyID REQ_REC# Defendant_Sex Defendant_Race Defendant_BirthYear  \\\n",
            "0        ADI00001        1             M              W                1986   \n",
            "1        ADI00007        3             M              B                1956   \n",
            "2        ADI00008        4             M              W                1990   \n",
            "3        CDI00036        6             M              B                1989   \n",
            "4        CDI00038        7             F              W                1988   \n",
            "\n",
            "  Defendant_Age  Defendant_AgeGroup Defendant_AgeatCurrentArrest  \\\n",
            "0            31                   3                           31   \n",
            "1            60                   6                           60   \n",
            "2            27                   3                           27   \n",
            "3            27                   3                           27   \n",
            "4            28                   3                           28   \n",
            "\n",
            "   Defendant_AttorneyTypeAtCaseClosure  Defendant_IndigencyStatus  ...  \\\n",
            "0                                   99                         99  ...   \n",
            "1                                    9                          9  ...   \n",
            "2                                    9                          9  ...   \n",
            "3                                    0                          0  ...   \n",
            "4                                    0                          0  ...   \n",
            "\n",
            "  NewFelonySexualAssaultArrest_OffDate  \\\n",
            "0                                        \n",
            "1                                        \n",
            "2                                        \n",
            "3                                        \n",
            "4                                        \n",
            "\n",
            "  NewFelonySexualAssaultArrest_ArrestDate  \\\n",
            "0                                           \n",
            "1                                           \n",
            "2                                           \n",
            "3                                           \n",
            "4                                           \n",
            "\n",
            "   NewFelonySexualAssaultArrest_DaysBetweenContactEventandOffDate  \\\n",
            "0                                                                   \n",
            "1                                                                   \n",
            "2                                                                   \n",
            "3                                                                   \n",
            "4                                                                   \n",
            "\n",
            "  NewFelonySexualAssaultArrest_DaysBetweenOffDateandArrestDate  \\\n",
            "0                                                999             \n",
            "1                                                999             \n",
            "2                                                999             \n",
            "3                                                999             \n",
            "4                                                999             \n",
            "\n",
            "   NewFelonySexualAssaultArrest_DaysBetweenReleaseDateandOffDate  \\\n",
            "0                                                999               \n",
            "1                                                999               \n",
            "2                                                999               \n",
            "3                                                999               \n",
            "4                                                999               \n",
            "\n",
            "   NewFelonySexualAssaultArrest_Disposition  \\\n",
            "0                                             \n",
            "1                                             \n",
            "2                                             \n",
            "3                                             \n",
            "4                                             \n",
            "\n",
            "   Intertnalindicator_ReasonforExcludingFromFollowUpAnalysis  \\\n",
            "0                                                  4           \n",
            "1                                                  5           \n",
            "2                                                  5           \n",
            "3                                                  5           \n",
            "4                                                  0           \n",
            "\n",
            "   CriminalHistoryRecordsReturnedorCMSRecordsFoundforIndividual  \\\n",
            "0                                                  1              \n",
            "1                                                  1              \n",
            "2                                                  1              \n",
            "3                                                  1              \n",
            "4                                                  1              \n",
            "\n",
            "  DispRecordFoundforChargesinOct2017Contact_Atleast1dispfound  \\\n",
            "0                                                  0            \n",
            "1                                                  1            \n",
            "2                                                  1            \n",
            "3                                                  1            \n",
            "4                                                  1            \n",
            "\n",
            "   CrimeCommission2021ReportClassificationofDefendants  \n",
            "0  Defendant could not be classified or tracked d...    \n",
            "1  Defendant Detained Entire Pre-Trial Period_Und...    \n",
            "2  Defendant Detained Entire Pre-Trial Period_Und...    \n",
            "3  Defendant Detained Entire Pre-Trial Period_Und...    \n",
            "4  New criminal offense punishable by incarcerati...    \n",
            "\n",
            "[5 rows x 709 columns]\n"
          ]
        }
      ],
      "source": [
        "# Question 3\n",
        "url = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv'\n",
        "pretrialdf = pd.read_csv(url,low_memory=False)\n",
        "print(pretrialdf.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "4ff41fb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1    19154\n",
            "0     3801\n",
            "9       31\n",
            "Name: released, dtype: int64\n",
            "[9 0 1]\n"
          ]
        }
      ],
      "source": [
        "pretrialdf = pretrialdf.rename(columns= {'WhetherDefendantWasReleasedPretrial': 'released'})\n",
        "released = pretrialdf['released']\n",
        "print(released.value_counts())\n",
        "print(released.unique()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "87b0e9ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Based on the codebook, the 9's are unclear. So, we should make these data nan\n",
        "released.replace(9, np.nan)\n",
        "print(sum(released.isnull()))\n",
        "pretrialdf['released'] = released\n",
        "del released"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "fe31b0fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4    8779\n",
            "0    8720\n",
            "1    4299\n",
            "2     914\n",
            "9     274\n",
            "Name: SentenceTypeAllChargesAtConvictionInContactEvent, dtype: int64 \n",
            "\n",
            "[' ' '60' '12' '.985626283367556' '36' '6' '24' '5.91375770020534' '120'\n",
            " '72' '11.9917864476386' '0' '2.95687885010267' '84' '108' '300' '240'\n",
            " '180' '4' '96' '2' '54' '.328542094455852' '44' '5' '115' '132' '48'\n",
            " '258' '34' '76' '.164271047227926' '.131416837782341' '111' '9' '3'\n",
            " '1.97125256673511' '36.9856262833676' '.0657084188911704'\n",
            " '35.4928131416838' '106.492813141684' '8' '35' '18.3141683778234' '480'\n",
            " '32' '93' '234' '732' '1.16427104722793' '4.6570841889117' '21' '7'\n",
            " '4.49281314168378' '18' '600' '43.1642710472279' '179' '52' '30' '20'\n",
            " '192' '702' '14' '55' '53' '11.9055441478439' '114' '35.0061601642711'\n",
            " '68' '.657084188911704' '46.6242299794661' '102' '65' '200' '57'\n",
            " '24.3285420944559' '12.1642710472279' '117' '81.4928131416838'\n",
            " '22.4928131416838' '1980' '3.6570841889117' '56' '10' '2.79260780287474'\n",
            " '1' '47' '22' '1500' '40' '284' '11' '118' '42' '162' '156'\n",
            " '47.2956878850103' '105' '51' '246' '29' '75' '324' '360'\n",
            " '34.4804928131417' '120.328542094456' '59.9260780287474' '66'\n",
            " '59.9917864476386' '660' '51.1642710472279' '14.9568788501027'\n",
            " '3.98562628336756' '78' '228' '1.47843942505133' '62' '4.8' '86' '168'\n",
            " '23' '33' '48.0328542094456' '720' '348' '1200' '27' '49' '87' '420' '63'\n",
            " '79.9260780287474' '57.0349075975359' '49.9712525667351'\n",
            " '59.4928131416838' '17' '238.492813141684' '60.9856262833676' '126' '45'\n",
            " '158' '216' '227' '42.9568788501027' '445' '70.952772073922' '516'\n",
            " '177.82135523614' '1752' '90' '1080' '141' '4.82956878850103' '230' '31'\n",
            " '2208' '52.5133470225873' '69' '26' '33.4928131416838' '140' '131' '344'\n",
            " '219' '101' '71' '59' '58' '120.197125256674' '67' '35.4004106776181'\n",
            " '3.28542094455852' '40.1642710472279' '91' '1.7741273100616' '155'\n",
            " '34.4928131416838' '81' '92.3285420944559' '3.5482546201232' '207' '74'\n",
            " '518' '28' '8.95687885010267' '237' '404.673511293634' '18.1642710472279'\n",
            " '10.7433264887064' '551' '39' '15' '124' '43' '176' '19.4928131416838'\n",
            " '482' '129' '88' '46' '45.8542094455852' '128.628336755647'\n",
            " '136.492813141684' '108.328542094456' '50' '363.663244353183' '288' '250'\n",
            " '107' '81.0225872689938' '444' '205' '10.6570841889117' '19'\n",
            " '66.9856262833676' '38.4928131416838' '264' '276' '173' '222' '144' '294'\n",
            " '336' '431' '450' '73' '99.3285420944559' '128' '30.8069815195072'\n",
            " '31.5256673511294' '127' '202' '55.3285420944559' '89' '242'\n",
            " '1.31416837782341' '1029' '.788501026694045' '194.858316221766' '399'\n",
            " '39.6570841889117' '56.95687885' '198' '120.985626283368'\n",
            " '47.6570841889117' '148' '6.8993839835729' '65.3285420944559'\n",
            " '5.95277207392197' '.0985626283367557' '3.32854209445585'\n",
            " '3.94250513347023' '12.9856262833676' '6.98562628336756'\n",
            " '13.1498973305955' '15.1642710472279' '17.1971252566735'\n",
            " '17.9137577002053' '104' '212' '24.6570841889117' '72.6570841889117'\n",
            " '2.98562628336756' '144.985626283368' '31.9712525667351' '183'\n",
            " '4.98562628336756' '11.8213552361396' '252' '12.394250513347'\n",
            " '42.4928131416838' '10.1642710472279' '11.1642710472279'\n",
            " '5.49281314168378' '59.6632443531827' '12.3285420944559'\n",
            " '48.9856262833676' '240.985626283368' '2.6570841889117' '540'\n",
            " '2.97125256673511' '6.32854209445585' '23.6632443531828'\n",
            " '133.657084188912' '35.3285420944559' '456' '103' '1.72279260780287'\n",
            " '12.6570841889117' '11.6570841889117' '60.3285420944559'\n",
            " '3.78850102669405' '576' '2.13141683778234' '492' '14.9856262833676'\n",
            " '24.9856262833676' '61.9712525667351' '5.6570841889117' '16'\n",
            " '42.1642710472279' '.492813141683778' '138' '13.3141683778234'\n",
            " '11.8932238193018' '5.32854209445585' '95' '62.6570841889117'\n",
            " '3.08829568788501' '11.8275154004107' '1.64271047227926'\n",
            " '47.9917864476386' '4.27104722792608' '8.32854209445585'\n",
            " '3.31416837782341' '70' '77' '1.09856262833676' '48.1642710472279'\n",
            " '27.4928131416838' '6.93839835728953' '1011' '.68993839835729'\n",
            " '1.1170431211499' '1.49281314168378' '4.16427104722793'\n",
            " '1.19712525667351' '4.07392197125257' '188' '11.3285420944559'\n",
            " '.0328542094455852' '432' '11.952772073922' '36.4928131416838'\n",
            " '23.9835728952772' '9.98562628336756' '98' '36.3285420944559' '112'\n",
            " '.394250513347023' '13' '.262833675564682' '13.7987679671458'\n",
            " '5.8870636550308' '354' '5.91991786447639' '24.1642710472279'\n",
            " '62.95687885' '4.59958932238193' '123' '2.32854209445585'\n",
            " '23.9240246406571' '204' '197' '174' '16.1498973305955' '840' '440'\n",
            " '98.95687885' '17.952772073922' '63.9425051334702' '60.1314168377823'\n",
            " '12.1314168377823' '172.952772073922' '.197125256673511'\n",
            " '138.164271047228' '4.92813141683778' '.919917864476386'\n",
            " '18.9856262833676' '6.6570841889117' '2.85420944558522'\n",
            " '8.91375770020534' '146' '12.4928131416838' '.558521560574949'\n",
            " '.722792607802875' '5.82135523613963' '84.9856262833676'\n",
            " '6.16427104722793' '15.9856262833676' '64.5585215605749'\n",
            " '38.299794661191' '11.958932238193' '3.1211498973306' '126.328542094456'\n",
            " '5.16427104722793' '64' '42.6570841889117' '312' '19.9712525667351'\n",
            " '82.3285420944559' '23.9712525667351' '17.6242299794661'\n",
            " '121.971252566735' '59.6550308008214' '1.32854209445585'\n",
            " '7.97125256673511' '1.91991786447639' '.525667351129363'\n",
            " '9.32854209445585' '42.9856262833676' '41.9137577002053'\n",
            " '72.9856262833676' '12.4784394250513' '5.19096509240246' '473'\n",
            " '16.6570841889117' '109' '86.3285420944559' '41' '1.90554414784394'\n",
            " '94.1642710472279' '302' '4.39425051334702' '10.8213552361396'\n",
            " '18.3285420944559' '154' '83' '110.956878850103' '226' '96.0328542094456'\n",
            " '4.82135523613963' '30.3285420944559' '37.9712525667351'\n",
            " '50.4640657084189' '286' '99' '99.4928131416838' '2.6611909650924'\n",
            " '70.9712525667351' '13.9712525667351' '23.6570841889117'\n",
            " '.459958932238193' '132.492813141684' '283' '49.3141683778234'\n",
            " '27.9856262833676' '38' '7.6570841889117' '83.6550308008214'\n",
            " '10.9199178644764' '162.328542094456' '37' '132.328542094456'\n",
            " '35.952772073922' '165' '10.9856262833676' '20.1642710472279'\n",
            " '2.59137577002053' '175' '180.985626283368' '10.3285420944559'\n",
            " '36.1642710472279' '120.657084188912' '232' '152' '8.98562628336756'\n",
            " '167' '11.0657084188912' '11.2032854209446' '5.19712525667351'\n",
            " '3.16427104722793' '60.1642710472279' '1.18275154004107'\n",
            " '21.1642710472279' '2.19712525667351' '4.19712525667351'\n",
            " '2.62833675564682' '119.952772073922' '119.958932238193'\n",
            " '9.49281314168378' '5.25667351129363' '15.3285420944559'\n",
            " '2.82135523613963' '192.985626283368' '48.6570841889117'\n",
            " '5.95687885010267' '2.29979466119097' '960' '2.36550308008214' '116'\n",
            " '19.5133470225873' '1.6570841889117']\n",
            "9053\n"
          ]
        }
      ],
      "source": [
        "# Question 4\n",
        "sentence = pretrialdf['SentenceTypeAllChargesAtConvictionInContactEvent']\n",
        "print(sentence.value_counts(), '\\n') \n",
        "\"\"\"\n",
        "Considering the codebook, there were 274 charges with types deemed as Not Applicable.\n",
        "Additionally, there are 8779 values in which the case was dismissed, which could explain if there was any missing data\n",
        "in ImposedSentenceAllChargeInContactEvent. If the case was deferred then there wouldn't be sentence term.\n",
        "\"\"\"\n",
        "\n",
        "imposed = pretrialdf['ImposedSentenceAllChargeInContactEvent']\n",
        "print(imposed.unique()) # one of the variables is ' ', possibly hinting at some empty data\n",
        "imposed = pd.to_numeric(imposed, errors=\"coerce\") # convert imposed into numeric\n",
        "imposed_nulls = imposed\n",
        "print(sum(imposed_nulls.isnull())) # There are 9053 null values. 274 + 8779 = 9053\n",
        "\n",
        "# # If we can't find out the type of charge, then we can't determine the sentence term, so we should use NaN for observations with type 9\n",
        "imposed = imposed.mask(sentence == 9, np.nan)\n",
        "\n",
        "# # If the charge was deferred, the subject received no sentence, so we should mark observations with type 4 as 0 for serving a sentence of 0 months\n",
        "imposed = imposed.mask(sentence == 4, 0)\n",
        "\n",
        "pretrialdf['ImposedSentenceAllChargeInContactEvent'] = imposed\n",
        "del imposed, sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5",
      "metadata": {
        "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5"
      },
      "source": [
        "**Q3.** Many important datasets contain a race variable, typically limited to a handful of values often including Black, White, Asian, Latino, and Indigenous. This question looks at data gathering efforts on this variable by the U.S. Federal government.\n",
        "\n",
        "1. How did the most recent US Census gather data on race?\n",
        "2. Why do we gather these data? What role do these kinds of data play in politics and society? Why does data quality matter?\n",
        "3. Please provide a constructive criticism of how the Census was conducted: What was done well? What do you think was missing? How should future large scale surveys be adjusted to best reflect the diversity of the population? Could some of the Census' good practices be adopted more widely to gather richer and more useful data?\n",
        "4. How did the Census gather data on sex and gender? Please provide a similar constructive criticism of their practices.\n",
        "5. When it comes to cleaning data, what concerns do you have about protected characteristics like sex, gender, sexual identity, or race? What challenges can you imagine arising when there are missing values? What good or bad practices might people adopt, and why?\n",
        "6. Suppose someone invented an algorithm to impute values for protected characteristics like race, gender, sex, or sexuality. What kinds of concerns would you have?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
